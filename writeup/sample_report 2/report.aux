\relax 
\citation{Dean2008}
\citation{Agrawal1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\citation{Agrawal1}
\citation{Agrawal1}
\citation{Han}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Association Rule Mining}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}MapReduce}{2}}
\citation{Agrawal1}
\citation{Han}
\citation{Agrawal1996}
\citation{Zaki1997}
\citation{Li2008}
\citation{Li2011}
\citation{Yang2010}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple association rule mining example where $\mathcal  {I} = \{i_1, i_2, i_3, i_4\}$. The database, $\mathcal  {D} = \{\tau _1, \tau _2\}$ is being mined with $minconf = .8$ The leftmost column shows the transactions in $\mathcal  {D}$. The middle column shows the candidate itemsets that are generated during frequent itemset mining. The rightmost column shows the resulting association rules and their associated confidence.\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example}{{1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{3}}
\citation{Yang2010}
\citation{Yang2010}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A diagram of our implementation.\relax }}{4}}
\newlabel{fig:overview}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Our Implementation}{4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Pseudocode for the Map method.\relax }}{5}}
\newlabel{map}{{1}{5}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Pseudocode for the Reduce method.\relax }}{5}}
\newlabel{reduce}{{2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A comparison of runtimes of a sequential FP-growth to our parallel implementation. All time are reported in seconds. DNF signifies that execution did not finish for that experiment.\relax }}{6}}
\newlabel{fig:performance}{{3}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Analysis}{6}}
\bibstyle{plain}
\bibdata{ref}
\bibcite{Yang2010}{1}
\bibcite{Li2011}{2}
\bibcite{Agrawal1996}{3}
\bibcite{Agrawal1}{4}
\bibcite{Dean2008}{5}
\newlabel{fig:data}{{4a}{7}}
\newlabel{sub@fig:data}{{(a)}{a}}
\newlabel{fig:cluster}{{4b}{7}}
\newlabel{sub@fig:cluster}{{(b)}{b}}
\newlabel{fig:speedup}{{4c}{7}}
\newlabel{sub@fig:speedup}{{(c)}{c}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Experimental evaluation of our method. In (a) we show how our method scales with increased data sizes and a fixed cluster size (16 m1.xlarge nodes). A line corresponding to linear (or ideal) scalability is plotted alongside. In (b), we show how demonstrate the performance of our method as cluster size is increased and data size is held at 512MB. In (c), we show the relative speedup of our method as we add more nodes to the cluster. An ideal speedup line is plotted as well. \relax }}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Data Scability}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Cluster Scability}}}{7}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Speedup}}}{7}}
\newlabel{fig:experiments}{{4}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{7}}
\bibcite{Han}{6}
\bibcite{Li2008}{7}
\bibcite{Zaki1997}{8}
